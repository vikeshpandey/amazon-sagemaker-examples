{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b02083d2-55a3-41e6-aed5-8ff633af6a59",
   "metadata": {},
   "source": [
    "## Get started with SageMaker\n",
    "\n",
    "This notebok is part of [Introductory blog on SageMaker Core](https://aws.amazon.com/blogs/machine-learning/introducing-sagemaker-core-a-new-object-oriented-python-sdk-for-amazon-sagemaker/).\n",
    "\n",
    "In this notebook you'll learn how SageMaker can be used to:\n",
    "\n",
    "1. Preprocess (and optionally explore) a dataset\n",
    "2. Train an XGBoost classifier for customer churn prediction, using a managed job with SageMaker Training, using a managed image.\n",
    "3. Create a managed real-time SageMaker endpoint.\n",
    "\n",
    "All SageMaker resources are created using the SageMaker Core SDK. You can find more information about sagemaker-core [here](https://sagemaker-core.readthedocs.io/en/latest/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0489c209-9628-4ddf-a849-8b973234126a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade pip -q\n",
    "%pip install sagemaker-core -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683f28ed-6c66-48c2-a24a-378764271f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import io\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from sagemaker_core.helper.session_helper import Session, get_execution_role\n",
    "from io import StringIO\n",
    "import pandas as pd\n",
    "from sagemaker_core.main.shapes import (\n",
    "    ProcessingInput,\n",
    "    ProcessingResources,\n",
    "    AppSpecification,\n",
    "    ProcessingS3Input,\n",
    "    ProcessingOutputConfig\n",
    ")\n",
    "from sagemaker_core.shapes import (\n",
    "    ProcessingResources,\n",
    "    ProcessingClusterConfig,\n",
    "    ProcessingOutput,\n",
    "    ProcessingS3Output,\n",
    ")\n",
    "\n",
    "from sagemaker_core.resources import ProcessingJob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314d959f-8c4a-4996-b167-24958d53417a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up region, role and bucket parameters used throughout the notebook.\n",
    "sagemaker_session = Session()\n",
    "region = sagemaker_session.boto_region_name\n",
    "role = get_execution_role()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "s3_client = \n",
    "\n",
    "print(f\"AWS region: {region}\")\n",
    "print(f\"Execution role: {role}\")\n",
    "print(f\"Default S3 bucket: {bucket}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b62649-4d89-4b6e-9f18-a48aa0bb27a4",
   "metadata": {},
   "source": [
    "## Preprocess dataset\n",
    "We'll use a synthetic dataset that AWS provides for customer churn prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f347ca27-68a3-41a1-998c-434d39f8245a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>NOTE:</b> This sample doesn't perform any exploratory data anlysis since how to preprocess the dataset is already known.\n",
    "    \n",
    "If you're interested in how to perform exploratory analysis, there's a section in the documentation for the sagemaker-python-sdk available that explores the dataset, [here](https://sagemaker-examples.readthedocs.io/en/latest/introduction_to_applying_machine_learning/xgboost_customer_churn/xgboost_customer_churn.html).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f74911-14c9-4ef8-bd18-db9664de7dcf",
   "metadata": {},
   "source": [
    "## Upload the processing code to S3\n",
    "\n",
    "The pre-processing code is already available in the current directory with the name `preprocess.py`. Have a look at the code to understand the processing logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed040f38-1e1b-4310-b5a6-2f49421952d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pre_processing_code_s3_uri = sagemaker_session.upload_data(\"preprocess.py\", key_prefix=\"sagemaker-core-intro-blog/processing/code\")\n",
    "pre_processing_code_s3_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f89929-0274-4248-9ac2-dadaac217222",
   "metadata": {},
   "source": [
    "### Create S3 variables for holding the processed data\n",
    "\n",
    "Create S3 variables for holding the processed data (train, validation and test)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930789de-cbfc-4ca6-b7a6-ad49d6f888da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "processed_train_data_uri = f\"s3://{bucket}/sagemaker-core-intro-blog/processing/output/train\"\n",
    "processed_validation_data_uri = f\"s3://{bucket}/sagemaker-core-intro-blog/processing/output/validation\"\n",
    "processed_test_data_uri = f\"s3://{bucket}/sagemaker-core-intro-blog/processing/output/test\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880c9f13-0c60-46cf-bc98-59c9141a9384",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Create processing job\n",
    "\n",
    "Below code submits a sagemaker processing job.\n",
    "\n",
    "1. ProcessingResources provides processing cluster details.\n",
    "2. AppSpecification provides processing container details. Here SKlearn processing container provided by sagemaker is used.\n",
    "3. Two objects of ProcessingInput specifying code and input data locations and configurations.\n",
    "4. ProcessingOutputConfig provides details on where the processed data will be stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce99f6a-934e-47a0-8033-b216d0e1a2a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Initialize a ProcessingJob resource\n",
    "current_timestamp = datetime.now()\n",
    "formatted_timestamp = current_timestamp.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "\n",
    "processing_job = ProcessingJob.create(\n",
    "    processing_job_name=f\"sagemaker-core-data-prep-{formatted_timestamp}\",\n",
    "    processing_resources=ProcessingResources(\n",
    "        cluster_config=ProcessingClusterConfig(\n",
    "            instance_count=1,\n",
    "            instance_type=\"ml.m5.xlarge\",\n",
    "            volume_size_in_gb=20\n",
    "        )\n",
    "    ),\n",
    "    app_specification=AppSpecification(\n",
    "        image_uri=f\"683313688378.dkr.ecr.{region}.amazonaws.com/sagemaker-scikit-learn:0.23-1-cpu-py3\",\n",
    "        container_entrypoint=[\"python3\", \"/opt/ml/processing/code/preprocess.py\"]\n",
    "    ),\n",
    "    role_arn=role,  # Intelligent default for execution role\n",
    "    processing_inputs=[\n",
    "        ProcessingInput(\n",
    "            input_name=\"input\",\n",
    "            s3_input=ProcessingS3Input(\n",
    "                s3_uri=f\"s3://sagemaker-example-files-prod-{region}/datasets/tabular/synthetic/churn.txt\",\n",
    "                s3_data_type=\"S3Prefix\",\n",
    "                local_path=\"/opt/ml/processing/input\",\n",
    "                s3_input_mode=\"File\"\n",
    "            ),\n",
    "        ),\n",
    "        ProcessingInput(\n",
    "            input_name=\"code\",\n",
    "            s3_input=ProcessingS3Input(\n",
    "                s3_uri=pre_processing_code_s3_uri,\n",
    "                s3_data_type=\"S3Prefix\",\n",
    "                local_path=\"/opt/ml/processing/code\",\n",
    "                s3_input_mode=\"File\"\n",
    "            ),\n",
    "        )\n",
    "    ],\n",
    "    processing_output_config= ProcessingOutputConfig(\n",
    "            outputs=[\n",
    "                ProcessingOutput(\n",
    "                    output_name=\"train\",\n",
    "                    s3_output=ProcessingS3Output(\n",
    "                        s3_uri=processed_train_data_uri,\n",
    "                        s3_upload_mode=\"EndOfJob\",\n",
    "                        local_path=\"/opt/ml/processing/output/train\"\n",
    "                    )\n",
    "                ),\n",
    "                ProcessingOutput(\n",
    "                    output_name=\"validation\",\n",
    "                    s3_output=ProcessingS3Output(\n",
    "                        s3_uri=processed_validation_data_uri,\n",
    "                        s3_upload_mode=\"EndOfJob\",\n",
    "                        local_path=\"/opt/ml/processing/output/validation\"\n",
    "                    )\n",
    "                ),\n",
    "                ProcessingOutput(\n",
    "                    output_name=\"test\",\n",
    "                    s3_output=ProcessingS3Output(\n",
    "                        s3_uri=processed_test_data_uri,\n",
    "                        s3_upload_mode=\"EndOfJob\",\n",
    "                        local_path=\"/opt/ml/processing/output/test\"\n",
    "                    )\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    ")\n",
    "\n",
    "# Wait for the ProcessingJob to complete\n",
    "processing_job.wait()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8c4139-244d-4827-b872-35fbeed664d8",
   "metadata": {},
   "source": [
    "## Train a classifier using XGBoost\n",
    "Use SageMaker Training and the managed XGBoost image to train a classifier. <br />\n",
    "More details on how to use SageMaker managed training with XGBoost can be found [here](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbf270c-20c0-4f82-a8a6-c2794ba57f70",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "  <b>NOTE:</b> For more information on using SageMaker managed container images and retrieving their ECR paths, \n",
    "  <a href=\"https://docs.aws.amazon.com/sagemaker/latest/dg-ecr-paths/sagemaker-algo-docker-registry-paths.html\" target=\"_blank\">here</a> \n",
    "  is the documentation. Please note that the image URI might need to be updated based on your selected AWS region.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "268583f2-2c20-401b-a57c-ee88fd402583",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = f\"683313688378.dkr.ecr.{region}.amazonaws.com/sagemaker-xgboost:1.7-1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85a91b5-4a68-43f4-b04a-991035cc35bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker_core.resources import TrainingJob\n",
    "from sagemaker_core.shapes import (\n",
    "    AlgorithmSpecification,\n",
    "    Channel,\n",
    "    DataSource,\n",
    "    S3DataSource,\n",
    "    ResourceConfig,\n",
    "    StoppingCondition,\n",
    "    OutputDataConfig,\n",
    ")\n",
    "\n",
    "job_name = \"xgboost-churn-\" + time.strftime(\n",
    "    \"%Y-%m-%d-%H-%M-%S\", time.gmtime()\n",
    ")  # Name of training job\n",
    "instance_type = \"ml.m4.xlarge\"  # SageMaker instance type to use for training\n",
    "instance_count = 1  # Number of instances to use for training\n",
    "volume_size_in_gb = 30  # Amount of storage to allocate to training job\n",
    "max_runtime_in_seconds = 600  # Maximum runtimt. Job exits if it doesn't finish before this\n",
    "s3_output_path = f\"s3://{bucket}\"  # bucket and optional prefix where the training job stores output artifacts, like model artifact.\n",
    "\n",
    "# Specify hyperparameters\n",
    "hyper_parameters = {\n",
    "    \"max_depth\": \"5\",\n",
    "    \"eta\": \"0.2\",\n",
    "    \"gamma\": \"4\",\n",
    "    \"min_child_weight\": \"6\",\n",
    "    \"subsample\": \"0.8\",\n",
    "    \"verbosity\": \"0\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"num_round\": \"100\",\n",
    "}\n",
    "\n",
    "# Create training job.\n",
    "training_job = TrainingJob.create(\n",
    "    training_job_name=job_name,\n",
    "    hyper_parameters=hyper_parameters,\n",
    "    algorithm_specification=AlgorithmSpecification(\n",
    "        training_image=image, training_input_mode=\"File\"\n",
    "    ),\n",
    "    role_arn=role,\n",
    "    input_data_config=[\n",
    "        Channel(\n",
    "            channel_name=\"train\",\n",
    "            content_type=\"csv\",\n",
    "            data_source=DataSource(\n",
    "                s3_data_source=S3DataSource(\n",
    "                    s3_data_type=\"S3Prefix\",\n",
    "                    s3_uri=processed_train_data_uri,\n",
    "                    s3_data_distribution_type=\"FullyReplicated\",\n",
    "                )\n",
    "            ),\n",
    "        ),\n",
    "        Channel(\n",
    "            channel_name=\"validation\",\n",
    "            content_type=\"csv\",\n",
    "            data_source=DataSource(\n",
    "                s3_data_source=S3DataSource(\n",
    "                    s3_data_type=\"S3Prefix\",\n",
    "                    s3_uri=processed_validation_data_uri,\n",
    "                    s3_data_distribution_type=\"FullyReplicated\",\n",
    "                )\n",
    "            ),\n",
    "        ),\n",
    "    ],\n",
    "    output_data_config=OutputDataConfig(s3_output_path=s3_output_path),\n",
    "    resource_config=ResourceConfig(\n",
    "        instance_type=instance_type,\n",
    "        instance_count=instance_count,\n",
    "        volume_size_in_gb=volume_size_in_gb,\n",
    "    ),\n",
    "    stopping_condition=StoppingCondition(max_runtime_in_seconds=max_runtime_in_seconds),\n",
    ")\n",
    "\n",
    "# Wait for the training job to complete\n",
    "# training_job.wait()\n",
    "training_job.wait(poll=60, timeout=None, logs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79e6746-6a03-4868-a22e-63a32bfcf599",
   "metadata": {},
   "source": [
    "## Use model artifacts for real time inference\n",
    "To use the model to perform real time inference, we need to:\n",
    "\n",
    "1. Create a SageMaker model with the same first-party image as we used for training, and the model artifacts produced during training. Indeed, such image can also be used to run inference\n",
    "2. Create an `EndpointConfig` using the SageMaker model object created in the previous step. The endpoint configuration specifies what SageMaker model to use, and what endpoint type.\n",
    "3. Create a SageMaker endpoint using `EndpointConfig` and other optional parameters.\n",
    "\n",
    "More information about SageMaker Endpoints can be found [here](https://docs.aws.amazon.com/sagemaker/latest/dg/realtime-endpoints.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b0db2b-4daf-4ee0-a035-b7108f3d7912",
   "metadata": {},
   "source": [
    "#### Create SageMaker Model\n",
    "\n",
    "Create a Model resource based on the model artifacts produced by the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270aa263-2a8f-4225-bcd6-56a57195ac63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker_core.resources import Model\n",
    "from sagemaker_core.shapes import ContainerDefinition\n",
    "\n",
    "model_s3_uri = training_job.model_artifacts.s3_model_artifacts  # Get URI of model artifacts from the training job.\n",
    "\n",
    "# Create SageMaker model: An image along with the model artifact to use.\n",
    "customer_churn_model = Model.create(\n",
    "    model_name=\"customer-churn-xgboost\",\n",
    "    primary_container=ContainerDefinition(image=image, model_data_url=model_s3_uri),\n",
    "    execution_role_arn=role,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfe8ade-8de6-487a-9b24-a2afbeaa8559",
   "metadata": {},
   "source": [
    "## Create endpoint configuration for real-time inference\n",
    "To create a SageMaker endpoint we first create an `EndpointConfig`. The endpoint configuration specifies what SageMaker model to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056e57bb-9edf-461e-97e8-40c9e5ebf39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker_core.resources import Endpoint, EndpointConfig\n",
    "from sagemaker_core.shapes import ProductionVariant\n",
    "\n",
    "endpoint_config_name = \"churn-prediction-endpoint-config\"  # Name of endpoint configuration\n",
    "model_name = customer_churn_model.get_name()  # Get name of SageMaker model created in previous step\n",
    "endpoint_name = \"customer-churn-endpoint\"  # Name of SageMaker endpoint\n",
    "\n",
    "endpoint_config = EndpointConfig.create(\n",
    "    endpoint_config_name=endpoint_config_name,\n",
    "    production_variants=[\n",
    "        ProductionVariant(\n",
    "            variant_name=\"AllTraffic\",\n",
    "            model_name=model_name,\n",
    "            instance_type=instance_type,\n",
    "            initial_instance_count=1,\n",
    "        )\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635cb615-f4e0-43fa-91d6-0b480a51fd16",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sagemaker_endpoint.wait_for_status(\n",
    "    target_status=\"InService\"\n",
    ")  # Wait for endpoint to become in service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd718d54-65ee-4b67-8556-196246356a68",
   "metadata": {},
   "source": [
    "#### Test live endpoint - with a sample record from test dataset\n",
    "\n",
    "Let us download the test data from S3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdbd048-014f-418d-8d88-fc329afc7ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client(\"s3\")\n",
    "s3.download_file(Bucket = bucket,\n",
    "                 Key = \"sagemaker-core-intro-blog/processing/output/train/test.csv\",\n",
    "                 Filename = \"test.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff78e4f-47cd-4f05-ba00-6ded32ad12a8",
   "metadata": {},
   "source": [
    "#### Invoke the endpoint\n",
    "\n",
    "Let us invoke the endpoint now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66fd20a-7016-4b55-9144-633461059b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pick a random record from CSV and convert it to string\n",
    "df = pd.read_csv(\"test.csv\", header=None)\n",
    "sample = df.sample(1)\n",
    "sample_payload = sample.to_csv(header=False, index=False).strip()\n",
    "\n",
    "# Send sample payload to live endpoint and parse response\n",
    "res = sagemaker_endpoint.invoke(body=sample_payload, content_type=\"text/csv\")\n",
    "result = res[\"Body\"].read().decode(\"utf-8\")\n",
    "result = result.split(\"\\n\")[:-1]\n",
    "\n",
    "# Compute performance metrics\n",
    "df_result = pd.DataFrame(result).astype(float)\n",
    "print_performance_metrics(df_result, test_target_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9d3ad7-4b67-405e-940a-0331fd28811f",
   "metadata": {},
   "source": [
    "## Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb90949-9b35-4e11-8d2a-6053beacb4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_endpoint.delete()\n",
    "endpoint_config.delete()\n",
    "customer_churn_model.delete()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
